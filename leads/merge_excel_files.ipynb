{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "# Script merges all XLSX files which are in the same folder\r\n",
                "# Creation date: 12 Oct 2022\r\n",
                "# Last modification: 12 Oct 2022\r\n",
                "#5531sek (92min) per 500 websites \r\n",
                "\r\n",
                "# Imports\r\n",
                "import pandas as pd\r\n",
                "import os\r\n",
                "import glob\r\n",
                "from urllib.parse import urlparse\r\n",
                "  \r\n",
                "path = os.getcwd() + \"\\\\output\" # Excel files must always be in \"output\" folder\r\n",
                "excel_files = glob.glob(os.path.join(path, \"*.xlsx\"))\r\n",
                "\r\n",
                "dataframes = []\r\n",
                "domains = []\r\n",
                "# loop over the list of excel_files\r\n",
                "for f in excel_files:\r\n",
                "    f_name = f.split(\"\\\\\")[-1] # Take file name\r\n",
                "    if f_name[:2] == \"g_\": # Intention is to only merge files that starts with \"g_\"\r\n",
                "        dataframes.append(pd.read_excel(f))\r\n",
                "\r\n",
                "try:\r\n",
                "    merged_df = pd.concat(dataframes).drop_duplicates(subset=['Website']) # Merge all files\r\n",
                "    merged_df = merged_df.drop(columns=[\"index\", \"Unnamed: 0\"]) # Drop unnecessary comuns\r\n",
                "    for website in merged_df[\"Website\"]: # Loop to take only domain from URL\r\n",
                "        domains.append(urlparse(website).netloc.replace(\"www.\", \"\").lower())\r\n",
                "    merged_df.insert(0, \"Domain\", domains) # Insert new column (loc, column_name, value)\r\n",
                "    merged_df.insert(3, \"Emails\", \"N/a\")\r\n",
                "    master_file = pd.read_excel(f'{path}\\\\master_file.xlsx')\r\n",
                "    master_merged = pd.concat([master_file, merged_df]).drop_duplicates(subset=['Website'], keep='first') # Keep first records (the ones that were in master_file)\r\n",
                "    master_merged.to_excel(f'{path}\\\\master_file.xlsx', index=False) # Save to Excel file\r\n",
                "except Exception as e:\r\n",
                "    print(e)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.13",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.13 64-bit (windows store)"
        },
        "interpreter": {
            "hash": "8065859a666a0a35ff186cc2b2b1d9fd6755a5e815cd2155f24ca932ca25e802"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}